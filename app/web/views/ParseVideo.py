import asyncio
import os
import time
import re

import yaml
from pywebio.input import *
from pywebio.output import *
from pywebio_battery import put_video

from app.web.views.ViewsUtils import ViewsUtils

from crawlers.hybrid.hybrid_crawler import HybridCrawler

HybridCrawler = HybridCrawler()

# è¯»å–ä¸Šçº§å†ä¸Šçº§ç›®å½•çš„é…ç½®æ–‡ä»¶
config_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(__file__)))), 'config.yaml')
with open(config_path, 'r', encoding='utf-8') as file:
    config = yaml.safe_load(file)


# æ ¡éªŒè¾“å…¥å€¼/Validate input value
def valid_check(input_data: str):
    # æ£€ç´¢å‡ºæ‰€æœ‰é“¾æ¥å¹¶è¿”å›åˆ—è¡¨/Retrieve all links and return a list
    url_list = ViewsUtils.find_url(input_data)
    # æ€»å…±æ‰¾åˆ°çš„é“¾æ¥æ•°é‡/Total number of links found
    total_urls = len(url_list)
    if total_urls == 0:
        warn_info = ViewsUtils.t('æ²¡æœ‰æ£€æµ‹åˆ°æœ‰æ•ˆçš„é“¾æ¥ï¼Œè¯·æ£€æŸ¥è¾“å…¥çš„å†…å®¹æ˜¯å¦æ­£ç¡®ã€‚',
                                 'No valid link detected, please check if the input content is correct.')
        return warn_info
    else:
        # æœ€å¤§æ¥å—æäº¤URLçš„æ•°é‡/Maximum number of URLs accepted
        max_urls = config['Web']['Max_Take_URLs']
        if total_urls > int(max_urls):
            warn_info = ViewsUtils.t(f'è¾“å…¥çš„é“¾æ¥å¤ªå¤šå•¦ï¼Œå½“å‰åªä¼šå¤„ç†è¾“å…¥çš„å‰{max_urls}ä¸ªé“¾æ¥ï¼',
                                     f'Too many links input, only the first {max_urls} links will be processed!')
            return warn_info


# é”™è¯¯å¤„ç†/Error handling
def error_do(reason: str, value: str) -> None:
    # è¾“å‡ºä¸€ä¸ªæ¯«æ— ç”¨å¤„çš„ä¿¡æ¯
    put_html("<hr>")
    put_error(
        ViewsUtils.t("å‘ç”Ÿäº†ä¸€ä¸ªé”™è¯¯ï¼Œç¨‹åºå°†è·³è¿‡è¿™ä¸ªè¾“å…¥å€¼ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªè¾“å…¥å€¼ã€‚",
                     "An error occurred, the program will skip this input value and continue to process the next input value."))
    put_html(f"<h3>âš {ViewsUtils.t('è¯¦æƒ…', 'Details')}</h3>")
    put_table([
        [
            ViewsUtils.t('åŸå› ', 'reason'),
            ViewsUtils.t('è¾“å…¥å€¼', 'input value')
        ],
        [
            reason,
            value
        ]
    ])
    put_markdown(ViewsUtils.t('> å¯èƒ½çš„åŸå› :', '> Possible reasons:'))
    put_markdown(ViewsUtils.t("- è§†é¢‘å·²è¢«åˆ é™¤æˆ–è€…é“¾æ¥ä¸æ­£ç¡®ã€‚",
                              "- The video has been deleted or the link is incorrect."))
    put_markdown(ViewsUtils.t("- æ¥å£é£æ§ï¼Œè¯·æ±‚è¿‡äºé¢‘ç¹ã€‚",
                              "- Interface risk control, request too frequent.")),
    put_markdown(ViewsUtils.t("- æ²¡æœ‰ä½¿ç”¨æœ‰æ•ˆçš„Cookieï¼Œå¦‚æœä½ éƒ¨ç½²åæ²¡æœ‰æ›¿æ¢ç›¸åº”çš„Cookieï¼Œå¯èƒ½ä¼šå¯¼è‡´è§£æå¤±è´¥ã€‚",
                              "- No valid Cookie is used. If you do not replace the corresponding Cookie after deployment, it may cause parsing failure."))
    put_markdown(ViewsUtils.t("> å¯»æ±‚å¸®åŠ©:", "> Seek help:"))
    put_markdown(ViewsUtils.t(
        "- ä½ å¯ä»¥å°è¯•å†æ¬¡è§£æï¼Œæˆ–è€…å°è¯•è‡ªè¡Œéƒ¨ç½²é¡¹ç›®ï¼Œç„¶åæ›¿æ¢`./app/crawlers/å¹³å°æ–‡ä»¶å¤¹/config.yaml`ä¸­çš„`cookie`å€¼ã€‚",
        "- You can try to parse again, or try to deploy the project by yourself, and then replace the `cookie` value in `./app/crawlers/platform folder/config.yaml`."))

    put_markdown(
        "- GitHub Issue: [Evil0ctal/Douyin_TikTok_Download_API](https://github.com/Evil0ctal/Douyin_TikTok_Download_API/issues)")
    put_html("<hr>")


# æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
def sanitize_filename(filename: str) -> str:
    """
    æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
    """
    # ç§»é™¤æˆ–æ›¿æ¢Windowså’ŒUnixç³»ç»Ÿä¸­çš„éæ³•å­—ç¬¦
    illegal_chars = r'[<>:"/\\|?*]'
    # å°†éæ³•å­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿
    filename = re.sub(illegal_chars, '_', filename)
    # ç§»é™¤å‰åç©ºæ ¼
    filename = filename.strip()
    # é™åˆ¶æ–‡ä»¶åé•¿åº¦ï¼ˆé¿å…è¿‡é•¿ï¼‰
    if len(filename) > 200:
        filename = filename[:200]
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤åç§°
    if not filename:
        filename = "video"
    return filename


# æ‰¹é‡ä¸‹è½½è§†é¢‘å‡½æ•°
async def download_all_videos(video_info_list):
    """
    å¼‚æ­¥æ‰¹é‡ä¸‹è½½æ‰€æœ‰è§†é¢‘
    video_info_list: åŒ…å«è§†é¢‘ä¿¡æ¯çš„åˆ—è¡¨ [{'url': url, 'desc': desc, 'type': type}, ...]
    """
    with use_scope('download_progress', clear=True):
        put_markdown(f"### {ViewsUtils.t('æ­£åœ¨å‡†å¤‡ä¸‹è½½...', 'Preparing to download...')}")
        
        # è¿‡æ»¤å‡ºåªæœ‰è§†é¢‘çš„é¡¹
        video_items = [item for item in video_info_list if item['type'] == ViewsUtils.t('è§†é¢‘', 'Video')]
        
        if not video_items:
            put_warning(ViewsUtils.t('æ²¡æœ‰æ‰¾åˆ°å¯ä¸‹è½½çš„è§†é¢‘ï¼', 'No videos found to download!'))
            return
        
        total = len(video_items)
        put_markdown(f"**{ViewsUtils.t('å‡†å¤‡ä¸‹è½½', 'Ready to download')} {total} {ViewsUtils.t('ä¸ªè§†é¢‘', 'videos')}**")
        put_html('<br>')
        
        # åˆ›å»ºä¸‹è½½ä»»åŠ¡
        put_markdown(ViewsUtils.t('### ğŸ“¥ å¼€å§‹ä¸‹è½½ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸‹è½½ç®¡ç†å™¨ä¸­æŸ¥çœ‹è¿›åº¦...', 
                                  '### ğŸ“¥ Download started, please check progress in browser download manager...'))
        
        # ä½¿ç”¨JavaScriptè§¦å‘å¤šä¸ªä¸‹è½½
        download_script = ""
        for idx, item in enumerate(video_items, 1):
            url = item['url']
            desc = item['desc']
            
            # æ¸…ç†æè¿°ä½œä¸ºæ–‡ä»¶å
            clean_desc = sanitize_filename(desc)
            
            # URLç¼–ç æ–‡ä»¶åï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
            import urllib.parse
            encoded_filename = urllib.parse.quote(clean_desc)
            
            # æ„å»ºä¸‹è½½é“¾æ¥ï¼Œå°†è‡ªå®šä¹‰æ–‡ä»¶åä½œä¸ºå‚æ•°ä¼ é€’
            download_url = f"/api/download?url={urllib.parse.quote(url)}&prefix=false&with_watermark=false&naming={encoded_filename}"
            
            # æ·»åŠ å»¶è¿Ÿä»¥é¿å…æµè§ˆå™¨é˜»æ­¢å¤šä¸ªä¸‹è½½ï¼ˆæ¯ä¸ªä¸‹è½½é—´éš”100msï¼‰
            delay = idx * 100
            download_script += f"""
                setTimeout(function() {{
                    var link = document.createElement('a');
                    link.href = '{download_url}';
                    link.download = '{clean_desc}.mp4';
                    document.body.appendChild(link);
                    link.click();
                    document.body.removeChild(link);
                }}, {delay});
            """
        
        # æ‰§è¡Œä¸‹è½½è„šæœ¬
        put_html(f"<script>{download_script}</script>")
        
        # æ˜¾ç¤ºä¸‹è½½åˆ—è¡¨
        put_html('<br>')
        put_markdown(f"### {ViewsUtils.t('ä¸‹è½½åˆ—è¡¨:', 'Download list:')}")
        
        download_table = [[ViewsUtils.t('åºå·', 'No.'), ViewsUtils.t('æ–‡ä»¶å', 'Filename')]]
        for idx, item in enumerate(video_items, 1):
            clean_desc = sanitize_filename(item['desc'])
            download_table.append([idx, f"{clean_desc}.mp4"])
        
        put_table(download_table)
        
        put_html('<br>')
        put_success(ViewsUtils.t(
            f'âœ… å·²è§¦å‘ {total} ä¸ªä¸‹è½½ä»»åŠ¡ï¼è¯·åœ¨æµè§ˆå™¨çš„ä¸‹è½½ç®¡ç†å™¨ä¸­æŸ¥çœ‹å’Œç®¡ç†ä¸‹è½½ã€‚',
            f'âœ… Triggered {total} download tasks! Please check and manage downloads in your browser\'s download manager.'
        ))
        
        put_info(ViewsUtils.t(
            'ğŸ’¡ æç¤ºï¼šéƒ¨åˆ†æµè§ˆå™¨å¯èƒ½ä¼šé˜»æ­¢å¤šä¸ªæ–‡ä»¶åŒæ—¶ä¸‹è½½ï¼Œè¯·åœ¨æµè§ˆå™¨æç¤ºä¸­å…è®¸å¤šä¸ªä¸‹è½½ã€‚',
            'ğŸ’¡ Tip: Some browsers may block multiple downloads. Please allow multiple downloads when prompted by your browser.'
        ))


def parse_video():
    placeholder = ViewsUtils.t(
        "æ‰¹é‡è§£æè¯·ç›´æ¥ç²˜è´´å¤šä¸ªå£ä»¤æˆ–é“¾æ¥ï¼Œæ— éœ€ä½¿ç”¨ç¬¦å·åˆ†å¼€ï¼Œæ”¯æŒæŠ–éŸ³å’ŒTikToké“¾æ¥æ··åˆï¼Œæš‚æ—¶ä¸æ”¯æŒä½œè€…ä¸»é¡µé“¾æ¥æ‰¹é‡è§£æã€‚",
        "Batch parsing, please paste multiple passwords or links directly, no need to use symbols to separate, support for mixing Douyin and TikTok links, temporarily not support for author home page link batch parsing.")
    input_data = textarea(
        ViewsUtils.t('è¯·å°†æŠ–éŸ³æˆ–TikTokçš„åˆ†äº«å£ä»¤æˆ–ç½‘å€ç²˜è´´äºæ­¤',
                     "Please paste the share code or URL of [Douyin|TikTok] here"),
        type=TEXT,
        validate=valid_check,
        required=True,
        placeholder=placeholder,
        position=0)
    url_lists = ViewsUtils.find_url(input_data)
    # è§£æå¼€å§‹æ—¶é—´
    start = time.time()
    # æˆåŠŸ/å¤±è´¥ç»Ÿè®¡
    success_count = 0
    failed_count = 0
    # é“¾æ¥æ€»æ•°
    url_count = len(url_lists)
    # è§£ææˆåŠŸçš„url
    success_list = []
    # è§£æå¤±è´¥çš„url
    failed_list = []
    # å­˜å‚¨è§†é¢‘ä¿¡æ¯ç”¨äºæ‰¹é‡ä¸‹è½½
    video_info_list = []
    
    # è¾“å‡ºä¸€ä¸ªæç¤ºæ¡
    with use_scope('loading_text'):
        # è¾“å‡ºä¸€ä¸ªåˆ†è¡Œç¬¦
        put_row([put_html('<br>')])
        put_warning(ViewsUtils.t('Serveré…±æ­£æ”¶åˆ°ä½ è¾“å…¥çš„é“¾æ¥å•¦ï¼(â—â€¢á´—â€¢â—)\næ­£åœ¨åŠªåŠ›å¤„ç†ä¸­ï¼Œè¯·ç¨ç­‰ç‰‡åˆ»...',
                                 'ServerChan is receiving your input link! (â—â€¢á´—â€¢â—)\nEfforts are being made, please wait a moment...'))
    # ç»“æœé¡µæ ‡é¢˜
    put_scope('result_title')
    # éå†é“¾æ¥åˆ—è¡¨
    for url in url_lists:
        # é“¾æ¥ç¼–å·
        url_index = url_lists.index(url) + 1
        # è§£æ
        try:
            data = asyncio.run(HybridCrawler.hybrid_parsing_single_video(url, minimal=True))
        except Exception as e:
            error_msg = str(e)
            with use_scope(str(url_index)):
                error_do(reason=error_msg, value=url)
            failed_count += 1
            failed_list.append(url)
            continue

        # åˆ›å»ºä¸€ä¸ªè§†é¢‘/å›¾é›†çš„å…¬æœ‰å˜é‡
        url_type = ViewsUtils.t('è§†é¢‘', 'Video') if data.get('type') == 'video' else ViewsUtils.t('å›¾ç‰‡', 'Image')
        platform = data.get('platform')
        desc = data.get('desc', 'video')
        
        # ä¿å­˜è§†é¢‘ä¿¡æ¯ç”¨äºæ‰¹é‡ä¸‹è½½
        video_info_list.append({
            'url': url,
            'desc': desc,
            'type': url_type
        })
        
        table_list = [
            [ViewsUtils.t('ç±»å‹', 'type'), ViewsUtils.t('å†…å®¹', 'content')],
            [ViewsUtils.t('è§£æç±»å‹', 'Type'), url_type],
            [ViewsUtils.t('å¹³å°', 'Platform'), platform],
            [f'{url_type} ID', data.get('aweme_id')],
            [ViewsUtils.t(f'{url_type}æè¿°', 'Description'), desc],
            [ViewsUtils.t('ä½œè€…æ˜µç§°', 'Author nickname'), data.get('author').get('nickname')],
            [ViewsUtils.t('ä½œè€…ID', 'Author ID'), data.get('author').get('unique_id')],
            [ViewsUtils.t('APIé“¾æ¥', 'API URL'),
             put_link(
                 ViewsUtils.t('ç‚¹å‡»æŸ¥çœ‹', 'Click to view'),
                 f"/api/hybrid/video_data?url={url}&minimal=false",
                 new_window=True)],
            [ViewsUtils.t('APIé“¾æ¥-ç²¾ç®€', 'API URL-Minimal'),
             put_link(ViewsUtils.t('ç‚¹å‡»æŸ¥çœ‹', 'Click to view'),
                      f"/api/hybrid/video_data?url={url}&minimal=true",
                      new_window=True)]

        ]
        # å¦‚æœæ˜¯è§†é¢‘/If it's video
        if url_type == ViewsUtils.t('è§†é¢‘', 'Video'):
            # æ·»åŠ è§†é¢‘ä¿¡æ¯
            wm_video_url_HQ = data.get('video_data').get('wm_video_url_HQ')
            nwm_video_url_HQ = data.get('video_data').get('nwm_video_url_HQ')
            if wm_video_url_HQ and nwm_video_url_HQ:
                table_list.insert(4, [ViewsUtils.t('è§†é¢‘é“¾æ¥-æ°´å°', 'Video URL-Watermark'),
                                      put_link(ViewsUtils.t('ç‚¹å‡»æŸ¥çœ‹', 'Click to view'),
                                               wm_video_url_HQ, new_window=True)])
                table_list.insert(5, [ViewsUtils.t('è§†é¢‘é“¾æ¥-æ— æ°´å°', 'Video URL-No Watermark'),
                                      put_link(ViewsUtils.t('ç‚¹å‡»æŸ¥çœ‹', 'Click to view'),
                                               nwm_video_url_HQ, new_window=True)])
            table_list.insert(6, [ViewsUtils.t('è§†é¢‘ä¸‹è½½-æ°´å°', 'Video Download-Watermark'),
                                  put_link(ViewsUtils.t('ç‚¹å‡»ä¸‹è½½', 'Click to download'),
                                           f"/api/download?url={url}&prefix=true&with_watermark=true",
                                           new_window=True)])
            table_list.insert(7, [ViewsUtils.t('è§†é¢‘ä¸‹è½½-æ— æ°´å°', 'Video Download-No-Watermark'),
                                  put_link(ViewsUtils.t('ç‚¹å‡»ä¸‹è½½', 'Click to download'),
                                           f"/api/download?url={url}&prefix=true&with_watermark=false",
                                           new_window=True)])
            # æ·»åŠ è§†é¢‘ä¿¡æ¯
            table_list.insert(0, [
                put_video(data.get('video_data').get('nwm_video_url_HQ'), poster=None, loop=True, width='50%')])
        # å¦‚æœæ˜¯å›¾ç‰‡/If it's image
        elif url_type == ViewsUtils.t('å›¾ç‰‡', 'Image'):
            # æ·»åŠ å›¾ç‰‡ä¸‹è½½é“¾æ¥
            table_list.insert(4, [ViewsUtils.t('å›¾ç‰‡æ‰“åŒ…ä¸‹è½½-æ°´å°', 'Download images ZIP-Watermark'),
                                  put_link(ViewsUtils.t('ç‚¹å‡»ä¸‹è½½', 'Click to download'),
                                           f"/api/download?url={url}&prefix=true&with_watermark=true",
                                           new_window=True)])
            table_list.insert(5, [ViewsUtils.t('å›¾ç‰‡æ‰“åŒ…ä¸‹è½½-æ— æ°´å°', 'Download images ZIP-No-Watermark'),
                                  put_link(ViewsUtils.t('ç‚¹å‡»ä¸‹è½½', 'Click to download'),
                                           f"/api/download?url={url}&prefix=true&with_watermark=false",
                                           new_window=True)])
            # æ·»åŠ å›¾ç‰‡ä¿¡æ¯
            no_watermark_image_list = data.get('image_data').get('no_watermark_image_list')
            for image in no_watermark_image_list:
                table_list.append(
                    [ViewsUtils.t('å›¾ç‰‡é¢„è§ˆ(å¦‚æ ¼å¼å¯æ˜¾ç¤º): ', 'Image preview (if the format can be displayed):'),
                     put_image(image, width='50%')])
                table_list.append([ViewsUtils.t('å›¾ç‰‡ç›´é“¾: ', 'Image URL:'),
                                   put_link(ViewsUtils.t('â¬†ï¸ç‚¹å‡»æ‰“å¼€å›¾ç‰‡â¬†ï¸', 'â¬†ï¸Click to open imageâ¬†ï¸'), image,
                                            new_window=True)])
        # å‘ç½‘é¡µè¾“å‡ºè¡¨æ ¼/Put table on web page
        with use_scope(str(url_index)):
            # æ˜¾ç¤ºè¿›åº¦
            put_info(
                ViewsUtils.t(f'æ­£åœ¨è§£æç¬¬{url_index}/{url_count}ä¸ªé“¾æ¥: ',
                             f'Parsing the {url_index}/{url_count}th link: '),
                put_link(url, url, new_window=True), closable=True)
            put_table(table_list)
            put_html('<hr>')
        scroll_to(str(url_index))
        success_count += 1
        success_list.append(url)
        
    # å…¨éƒ¨è§£æå®Œæˆè·³å‡ºforå¾ªç¯/All parsing completed, break out of for loop
    with use_scope('result_title'):
        put_row([put_html('<br>')])
        put_markdown(ViewsUtils.t('## ğŸ“è§£æç»“æœ:', '## ğŸ“Parsing results:'))
        put_row([put_html('<br>')])
    with use_scope('result'):
        # æ¸…é™¤è¿›åº¦æ¡
        clear('loading_text')
        # æ»šåŠ¨è‡³result
        scroll_to('result')
        # forå¾ªç¯ç»“æŸï¼Œå‘ç½‘é¡µè¾“å‡ºæˆåŠŸæé†’
        put_success(ViewsUtils.t('è§£æå®Œæˆå•¦ â™ª(ï½¥Ï‰ï½¥)ï¾‰\nè¯·æŸ¥çœ‹ä»¥ä¸‹ç»Ÿè®¡ä¿¡æ¯ï¼Œå¦‚æœè§‰å¾—æœ‰ç”¨çš„è¯è¯·åœ¨GitHubä¸Šå¸®æˆ‘ç‚¹ä¸€ä¸ªStarå§ï¼',
                                 'Parsing completed â™ª(ï½¥Ï‰ï½¥)ï¾‰\nPlease check the following statistics, and if you think it\'s useful, please help me click a Star on GitHub!'))
        # å°†æˆåŠŸï¼Œå¤±è´¥ä»¥åŠæ€»æ•°é‡æ˜¾ç¤ºå‡ºæ¥å¹¶ä¸”æ˜¾ç¤ºä¸ºä»£ç æ–¹ä¾¿å¤åˆ¶
        put_markdown(
            f'**{ViewsUtils.t("æˆåŠŸ", "Success")}:** {success_count} **{ViewsUtils.t("å¤±è´¥", "Failed")}:** {failed_count} **{ViewsUtils.t("æ€»æ•°é‡", "Total")}:** {success_count + failed_count}')
        # æˆåŠŸåˆ—è¡¨
        if success_count != url_count:
            put_markdown(f'**{ViewsUtils.t("æˆåŠŸåˆ—è¡¨", "Success list")}:**')
            put_code('\n'.join(success_list))
        # å¤±è´¥åˆ—è¡¨
        if failed_count > 0:
            put_markdown(f'**{ViewsUtils.t("å¤±è´¥åˆ—è¡¨", "Failed list")}:**')
            put_code('\n'.join(failed_list))
        # å°†url_listsæ˜¾ç¤ºä¸ºä»£ç æ–¹ä¾¿å¤åˆ¶
        put_markdown(ViewsUtils.t('**ä»¥ä¸‹æ˜¯æ‚¨è¾“å…¥çš„æ‰€æœ‰é“¾æ¥ï¼š**', '**The following are all the links you entered:**'))
        put_code('\n'.join(url_lists))
        # è§£æç»“æŸæ—¶é—´
        end = time.time()
        # è®¡ç®—è€—æ—¶,ä¿ç•™ä¸¤ä½å°æ•°
        time_consuming = round(end - start, 2)
        # æ˜¾ç¤ºè€—æ—¶
        put_markdown(f"**{ViewsUtils.t('è€—æ—¶', 'Time consuming')}:** {time_consuming}s")
        
        # æ·»åŠ æ‰¹é‡ä¸‹è½½æŒ‰é’®ï¼ˆä»…å½“æœ‰è§†é¢‘æ—¶æ˜¾ç¤ºï¼‰
        video_count = sum(1 for item in video_info_list if item['type'] == ViewsUtils.t('è§†é¢‘', 'Video'))
        if video_count > 0:
            put_html('<br>')
            put_button(
                ViewsUtils.t(f'ğŸ“¥ ä¸€é”®ä¸‹è½½å…¨éƒ¨æ— æ°´å°è§†é¢‘ ({video_count}ä¸ª)', 
                           f'ğŸ“¥ Download All No-Watermark Videos ({video_count})'), 
                onclick=lambda: asyncio.run(download_all_videos(video_info_list)), 
                color='primary', 
                outline=True
            )
        
        put_html('<br>')
        # æ”¾ç½®ä¸€ä¸ªæŒ‰é’®ï¼Œç‚¹å‡»åè·³è½¬åˆ°é¡¶éƒ¨
        put_button(ViewsUtils.t('å›åˆ°é¡¶éƒ¨', 'Back to top'), onclick=lambda: scroll_to('1'), color='success',
                   outline=True)
        # è¿”å›ä¸»é¡µé“¾æ¥
        put_link(ViewsUtils.t('å†æ¥ä¸€æ³¢ (ã¤Â´Ï‰`)ã¤', 'Another wave (ã¤Â´Ï‰`)ã¤'), '/')
        
        # ä¸‹è½½è¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
        put_scope('download_progress')